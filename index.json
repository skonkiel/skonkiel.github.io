[{"authors":["admin"],"categories":null,"content":"Stacy Konkiel is a Senior Data Analyst at Altmetric. Stacy is experienced in translating organizational values and goals to measurable outcomes, presenting to and collaborating with global teams, and analyzing, visualizing, and explaining complex data to help others understand organizational impact. Stacy co-founded the HuMetricsHSS initiative and Metrics Toolkit. Previously, Stacy worked with teams at Our Research (Impactstory), Indiana University \u0026amp; PLOS.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://skonkiel.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Stacy Konkiel is a Senior Data Analyst at Altmetric. Stacy is experienced in translating organizational values and goals to measurable outcomes, presenting to and collaborating with global teams, and analyzing, visualizing, and explaining complex data to help others understand organizational impact. Stacy co-founded the HuMetricsHSS initiative and Metrics Toolkit. Previously, Stacy worked with teams at Our Research (Impactstory), Indiana University \u0026amp; PLOS.","tags":null,"title":"Stacy Konkiel","type":"authors"},{"authors":["Nicky Agate","Rebecca Kennison","Stacy Konkiel","Christopher P. Long","Jason Rhody","Simone Sacchi","Penelope Weber"],"categories":[],"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607881836,"objectID":"985e234abb929cde1b9d4ec07dee8ed5","permalink":"https://skonkiel.github.io/publication/agate-transformative-2020/","publishdate":"2020-12-13T17:50:36.029228Z","relpermalink":"/publication/agate-transformative-2020/","section":"publication","summary":"The current mechanisms by which scholars and their work are evaluated across higher education are unsustainable and, we argue, increasingly corrosive. Relying on a limited set of proxy measures, current systems of evaluation fail to recognize and reward the many dependencies upon which a healthy scholarly ecosystem relies. Drawing on the work of the HuMetricsHSS Initiative, this essay argues that by aligning values with practices, recognizing the vital processes that enrich the work produced, and grounding our indicators of quality in the degree to which we in the academy live up to the values for which we advocate, a values-enacted approach to research production and evaluation has the capacity to reshape the culture of higher education.","tags":[],"title":"The transformative power of values-enacted scholarship","type":"publication"},{"authors":["Stacy Konkiel"],"categories":null,"content":"","date":1605657600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605657600,"objectID":"de049b1b6f9a3039dfa6babdf44d0f81","permalink":"https://skonkiel.github.io/talk/ismpp-u-2020/","publishdate":"2020-04-12T16:26:02-05:00","relpermalink":"/talk/ismpp-u-2020/","section":"talk","summary":"Discusses the implications of new advances in altmetrics for the biopharmaceutical industry in general and publication planners in particular. (Accessible for ISMPP members only.)","tags":[],"title":"Altmetrics: The state of the art for publication planning","type":"talk"},{"authors":null,"categories":["Work \u0026 Research"],"content":"In 2018, I wrote a post for The Bibliomagician blog on identifying authors\u0026rsquo; genders based on name analyses, based on a lively discussion on the LIS-Bibliometrics listserv. I\u0026rsquo;m reposting the blog post here under a CC-BY license.\nRecently on the LIS-Bibliometrics listserv, Ruth Harrison (Imperial College London) posed a question on behalf of a patron who was interested in identifying authors\u0026rsquo; genders based upon names listed on ~2,000 journal articles–too large a corpus for manual analysis. The community weighed in with many good suggestions for ways to approach a large scale gender analysis for author names. We thought it would be helpful to others to share what Ruth learned (with permission from the original posters).\nHere are some recommendations from LIS-Bibliometrics listserv members on the best places to find author names, APIs and software you can use to analyze gender, consultants you can hire the analysis out to, and previous approaches to analysis from other gender bibliometrics researchers.\nWhere to find author names lists  Web of Science was most recommended as being a good way to download full author names for publication lists. Programmatic access via the Web of Science API is usually available for licensing (libraries are usually the purchasers of Web of Science access for institutions, so you should contact your library to inquire as to whether API access is included in your institution\u0026rsquo;s contract).\n We would be remiss if we did not point out the challenges that face anyone seeking to do a study that determines a person\u0026rsquo;s gender, based on name alone.\n New citation index Dimensions also makes authors\u0026rsquo; full names available for download (though only for up to 50 papers at once in the free version of the app) and via the Dimensions API, which is freely available for those doing scientometrics research.\nOn the other hand, listserv members pointed out that Scopus only makes authors\u0026rsquo; first initials available both in metadata downloads for publication lists and via the Scopus API. Therefore, it is unsuitable to use in isolation for finding author names.\nAPIs and software Automated gender analysis requires a bit of programming knowledge (or at least a willingness to learn). In particular, calling APIs and parsing publication metadata are two essential programming skills.\n Gender API is a recommended service that allows you to look up the likely gender (and degree of confidence) for a particular name or list of names. For example, you could query the name \u0026ldquo;Diana\u0026rdquo; and learn that the name is classified as \u0026lsquo;female\u0026rsquo;, with a 93% accuracy rate based on a sample of 523 names. The providers offer clients for interacting with the API in PHP, Python, and several other programming languages.\n Namsor is another recommended API for looking up gender based on names, and it has the added feature of looking up ethnicity, as well. The free API allows for a limited number of monthly calls; you can also pay for API access to increase your API call limit.\n GenderChecker is a recommended name list that can be downloaded for less than $200 USD, then analyzed. As one listserv poster explained, \u0026ldquo;It\u0026rsquo;s not 100 percent accurate, but works for most American/European first names, especially if you have a large dataset. Be very careful with Chinese/Japanese/Korean names; most of the time they should be neutral unless you further checked.\u0026rdquo;\n Genderize.io is yet another API that was not recommended by listserv members, but appears in several recent studies and reports. The Genderize database reportedly contains 216,286 distinct names across 79 countries and 89 languages. It is free to use but rate-limited to 1000 requests per day.\nFinally, the recommended Python package SexMachine allows you to look up the gender for around 40,000 names. For each name you query, you will get a response for one of the following categories: andy (androgynous), male, female, mostly_male, or mostly_female. For example, the query \u0026ldquo;Paul\u0026rdquo; would return \u0026ldquo;male\u0026rdquo;, whereas the name \u0026ldquo;Stacy\u0026rdquo; would return \u0026ldquo;mostly_female\u0026rdquo;.\nOther gender researchers\u0026rsquo; approaches Listserv members also suggested that Ruth and her patron look to existing author gender analysis studies to find methods to borrow. Two in particular–a 2013 commentary from Nature, and a more recent Elsevier report–were the most mentioned:\n Larivière, V., Ni, C., Gingras, Y., Cronin, B., \u0026amp; Sugimoto, C. R. (2013). Bibliometrics: Global gender disparities in science. Nature, 504(7479), 211. (2017). Gender in the global research landscape.  The Nature study\u0026rsquo;s supplementary files include a thorough discussion of how to parse Web of Science names data for a variety of countries of origin.\nOne listserv respondent pointed out that \u0026ldquo;The Elsevier report\u0026rsquo;s methodology implies they didn\u0026rsquo;t have an easier way to [identify author gender] (\u0026ldquo;Scopus Author Profiles were combined with gender-name data from social media, applied onomastics, and Wikipedia\u0026rdquo;).\u0026rdquo; More details on the study\u0026rsquo;s methods can be found in a report appendix. Particularly useful is a discussion of the various name-gender APIs suitability for multi-country analysis.\nConsultants For those who want to hire out the work, Science-Metrix, Elsevier Analytical Services, and Digital Science Consultancy are all businesses that offer a variety of bibliometrics analysis services, which may include gender analysis. Contact the consultancies themselves for more information.\nChallenges We would be remiss if we did not point out the challenges that face anyone seeking to do a study that determines a person\u0026rsquo;s gender, based on name alone. First and foremost, there is the question of ethics: does this kind of study rob authors of their right to be identified as a particular gender that might not match the expected gender for someone with their name?\nRelated to that issue is the problem of the assumption of a gender binary. All studies in this area tend to identify authors as \u0026ldquo;Male\u0026rdquo;, \u0026ldquo;Female\u0026rdquo;, \u0026ldquo;Unisex\u0026rdquo; (as in, a name that is suitable for both men and women), and \u0026ldquo;Unknown\u0026rdquo;. How can researchers more accurately identify the gender of someone who identifies as genderqueer or agender, for example? It doesn\u0026rsquo;t seem possible to do so using a simple names analysis, meaning that these kinds of studies should be approached and described with that caveat in mind.\nThen there are technical issues related to the dearth of useful author metadata and regional name-gender data. \u0026ldquo;What about cases where the author info only includes initials?\u0026rdquo; one listserv respondent wrote. Other respondents pointed out that many name-gender analysis tools are biased towards Western names, making it difficult to do accurate analysis on authors from other areas of the world.\n","date":1604699497,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604699497,"objectID":"07e7393807fb74db1c143dd7b7ac685f","permalink":"https://skonkiel.github.io/identify-author-gender-data-analysis/","publishdate":"2020-11-06T21:51:37Z","relpermalink":"/identify-author-gender-data-analysis/","section":"post","summary":"In 2018, I wrote a post for The Bibliomagician blog on identifying authors\u0026rsquo; genders based on name analyses, based on a lively discussion on the LIS-Bibliometrics listserv. I\u0026rsquo;m reposting the blog post here under a CC-BY license.\nRecently on the LIS-Bibliometrics listserv, Ruth Harrison (Imperial College London) posed a question on behalf of a patron who was interested in identifying authors\u0026rsquo; genders based upon names listed on ~2,000 journal articles–too large a corpus for manual analysis.","tags":null,"title":"A guide to identifying author gender for bibliometric analyses","type":"post"},{"authors":["Stacy Konkiel"],"categories":[],"content":"","date":1598918400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607881836,"objectID":"30d1ad4a76253497b3a5008920269b62","permalink":"https://skonkiel.github.io/publication/konkiel-assessing-2020/","publishdate":"2020-12-13T17:50:35.804639Z","relpermalink":"/publication/konkiel-assessing-2020/","section":"publication","summary":"Article: Assessing the Impact and Quality of Research Data Using Altmetrics and Other Indicators","tags":[],"title":"Assessing the Impact and Quality of Research Data Using Altmetrics and Other Indicators","type":"publication"},{"authors":["Stacy Konkiel","Heather Coates","Robin Champieux"],"categories":[],"content":"","date":1586563200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586563200,"objectID":"6e7246b5768bd53535fca41176068b41","permalink":"https://skonkiel.github.io/project/metrics-toolkit/","publishdate":"2020-04-11T00:00:00Z","relpermalink":"/project/metrics-toolkit/","section":"project","summary":"A resource for researchers and evaluators that provides guidance for demonstrating and evaluating claims of research impact.","tags":[],"title":"Metrics Toolkit","type":"project"},{"authors":["Stephanie Guichard","Stacy Konkiel"],"categories":null,"content":"","date":1581465600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581465600,"objectID":"9f0b460c075717a9c110b6908bf083a9","permalink":"https://skonkiel.github.io/talk/eresearchnz-2020/","publishdate":"2020-04-12T15:53:19-05:00","relpermalink":"/talk/eresearchnz-2020/","section":"talk","summary":"How can we use data science to measure research outcomes at scale? Can quantitative data be used at all to understand research’s “impact” in its truest sense? In this presentation, we will share how—by asking the right questions, using the right data, and understanding data science’s strengths and limitations—New Zealanders can measure their success towards achieving health research outcomes, and even forecast future success.","tags":[],"title":"Data-intensive approaches to finding and predicting research outcomes for New Zealand health research","type":"talk"},{"authors":["Christian Herzog","Daniel Hook","Stacy Konkiel"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"b5f336b42ecb4c8cceaa554eab056dda","permalink":"https://skonkiel.github.io/publication/herzog-dimensions-2020/","publishdate":"2020-04-12T22:26:37.929885Z","relpermalink":"/publication/herzog-dimensions-2020/","section":"publication","summary":"","tags":null,"title":"Dimensions: Bringing down barriers between scientometricians and data","type":"publication"},{"authors":[],"categories":[],"content":"","date":1577750400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577750400,"objectID":"0c3d4f05b2353d8421c0f9425738c8f4","permalink":"https://skonkiel.github.io/project/humetricshss/","publishdate":"2019-12-31T00:00:00Z","relpermalink":"/project/humetricshss/","section":"project","summary":"Co-founder and co-PI from 2016-2019. Rethinking humane indicators of excellence in the humanities and social sciences.","tags":[],"title":"HuMetricsHSS","type":"project"},{"authors":["Stacy Konkiel"],"categories":null,"content":"","date":1551830400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551830400,"objectID":"a04fd7179c15b98a15827b4153c52f6f","permalink":"https://skonkiel.github.io/talk/erl-2019/","publishdate":"2020-04-12T16:07:04-05:00","relpermalink":"/talk/erl-2019/","section":"talk","summary":"A crash course in working with APIs, Jupyter Notebooks, and Plotly/Dash to create scholcomm reports \u0026 dashboards.","tags":[],"title":"Working with the Dimensions and Altmetric APIs to search, visualize, and integrate research information across library systems","type":"talk"},{"authors":["Stacy Konkiel","Mike Taylor"],"categories":null,"content":"","date":1541635200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541635200,"objectID":"6e12c58594d23026e6683002fd02de77","permalink":"https://skonkiel.github.io/talk/nordic-bibliometrics-2019/","publishdate":"2020-04-12T16:26:02-05:00","relpermalink":"/talk/nordic-bibliometrics-2019/","section":"talk","summary":"Comparing national trends in Nordic innovation.","tags":[],"title":"Measuring knowledge mobilization for Nordic research using patent and policy indicators","type":"talk"},{"authors":["Stacy Konkiel"],"categories":null,"content":"","date":1541030400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541030400,"objectID":"9aead4fa855ff4551cc9f550040be51e","permalink":"https://skonkiel.github.io/publication/konkiel-approaches-2018/","publishdate":"2020-04-12T22:26:37.923261Z","relpermalink":"/publication/konkiel-approaches-2018/","section":"publication","summary":"There are many complexities and challenges associated with developing ‘humane’ research evaluation metrics in the humanities. This monumental task can only be addressed by reverse engineering evaluation metrics based upon the practices and values that funders, institutions, professional societies and individuals want to encourage in their disciplines. The work of the HuMetricsHSS initiative is described in this article as a framework for doing so.","tags":["bibliometrics","evaluation","indicators","research metrics","Humanities"],"title":"Approaches to creating ‘humane’ research evaluation metrics for the humanities","type":"publication"},{"authors":["Robin Champieux","Heather Coates","Stacy Konkiel","Karen Gutzman"],"categories":null,"content":"","date":1538352000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538352000,"objectID":"43e3b513b79f89843a90f828c9528f59","permalink":"https://skonkiel.github.io/publication/champieux-metrics-2018/","publishdate":"2020-04-12T22:26:37.924135Z","relpermalink":"/publication/champieux-metrics-2018/","section":"publication","summary":"While research metrics may seem well established in the scholarly landscape, it can be challenging to understand how they should be used and how they are calculated. The Metrics Toolkit is an online evidence-based resource for researchers, librarians, evaluators, and administrators in their work to demonstrate or assess the impact of research.This article was selected by the Virtual Projects Advisory Committee of technology experts after an annual call for projects in MLA-FOCUS and announcements to encourage submissions from all types of libraries.","tags":["Bibliometrics","Altmetrics","Research Impact","Research Evaluation","Alternative Metrics"],"title":"Metrics Toolkit: an online evidence-based resource for navigating the research metrics landscape","type":"publication"},{"authors":null,"categories":["Work \u0026 Research"],"content":"The Journal of Librarianship and Scholarly Communication just published “ Scholarly Communication Librarians’ Relationship with Research Impact Indicators: An Analysis of a National Survey of Academic Librarians in the United States“.\nThis is the final publication related a topic I’ve been working on since 2013 (!), when I first realized that although academic librarians were interested in research metrics, no one had yet studied the reality of how they were using these kinds of indicators in their day-to-day jobs and in support of their own careers.\nAlong the way, I’ve been privileged to work with Sarah Sutton and Rachel Miles (and for a short period, Michael Levine-Clark) on a series of publications and presentations that include:\n  “Is What’s “Trending” What’s Worth Purchasing? Insights from a National Study of Collection Development Librarians” in The Serials Librarian (which we also presented upon at NASIG 2016 in Albuquerque)  “Awareness of Altmetrics among LIS Scholars and Faculty” in Journal of Education for Library and Information Science (which we compared to librarians at ER\u0026amp;L 2016 in Austin, TX) “ What’s used to gauge when engaging?: Determining academic librarian roles in research assessment reporting services“, presented at the 2016 Bibliometrics and Research Assessment Symposium in Bethesda, MD. “ Scholarly Communication Librarians’ Relationship with Research Impact Metrics,” a panel presentation at ‘Finding Meaning in Metrics’ at ALA Annual 2016 in Orlando, FL “Use of Altmetrics in US-based academic libraries,” a presentation at the Second Altmetrics Conference in Amsterdam (summarized on the Altmetrics Conference blog by Ian Mulvaney) “ Myth vs. reality: Altmetrics and librarians,” a presentation at the Altmetrics15 workshop in Amsterdam  We ultimately learned that:\n Your seniority/years of experience has no effect upon how familiar you are likely to be with various research metrics Librarians and LIS educators alike are more familiar with traditional research impact metrics like the JIF than they are with altmetrics Altmetrics are least likely to be used for collection development, though this is a use case I’ve been promoting for a long time The more scholcomm-related duties you have in your job, the more you’ll use metrics of all kinds Altmetric is the most popular altmetrics database used by librarians 😎  Sarah and Rachel plan to carry this path of research forward, expanding the scope of the study to include librarians worldwide, and also possibly looking at library promotion and tenure documents’ discussion of metrics. I wish them the very best and want to once again express my gratitude towards them as collaborators: Ladies, I hope to work with you both again in the future!\n  ","date":1531864297,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531864297,"objectID":"b3a9b97198066194ebfa20cc3e06c01a","permalink":"https://skonkiel.github.io/librarians-and-research-metrics-sutton-miles/","publishdate":"2018-07-17T21:51:37Z","relpermalink":"/librarians-and-research-metrics-sutton-miles/","section":"post","summary":"The Journal of Librarianship and Scholarly Communication just published “ Scholarly Communication Librarians’ Relationship with Research Impact Indicators: An Analysis of a National Survey of Academic Librarians in the United States“.\nThis is the final publication related a topic I’ve been working on since 2013 (!), when I first realized that although academic librarians were interested in research metrics, no one had yet studied the reality of how they were using these kinds of indicators in their day-to-day jobs and in support of their own careers.","tags":null,"title":"New article: “Scholarly Communication Librarians’ Relationship with Research Impact Indicators: An Analysis of a National Survey of Academic Librarians in the United States”","type":"post"},{"authors":["Sarah Sutton","Rachel Miles","Stacy Konkiel"],"categories":null,"content":"","date":1517443200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517443200,"objectID":"b5d149fa31aadd0150067c0794d1d79d","permalink":"https://skonkiel.github.io/publication/sutton-awareness-2018/","publishdate":"2020-04-12T22:26:37.925916Z","relpermalink":"/publication/sutton-awareness-2018/","section":"publication","summary":"Altmetrics track the attention paid to scholarship via mentions in social media, the press, and other non-traditional venues. For library and information science (LIS) faculty, altmetrics are also ...","tags":null,"title":"Awareness of Altmetrics among LIS Scholars and Faculty","type":"publication"},{"authors":["Stacy Konkiel","Stephanie Guichard"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"554eb3969c2c08741882cbc565a11802","permalink":"https://skonkiel.github.io/publication/konkiel-altmetrics-2018/","publishdate":"2020-04-12T22:26:37.9249Z","relpermalink":"/publication/konkiel-altmetrics-2018/","section":"publication","summary":"Purpose Altmetrics can offer organizations a unique opportunity to understand the non-traditional scholarly and public influence of their institutions’ research. This paper aims to look at bibliometrics and altmetrics for New Zealand research published in 2016 to understand the country’s research’s reach in social media, mainstream media and public policy, as well as more traditional measures of research impact such as university rankings, citations and publications. Design/methodology/approach Research insights platform Dimensions was searched for author affiliations and publication dates for papers published in 2016 by New Zealand researchers (n = 10,934). The study then used Dimensions to perform citation analysis and Altmetric Explorer to find altmetrics for these journal articles, and to generate visualizations to better interrogate the data set. Findings Of the 10,934 papers published in 2016 by New Zealand (2016 NZ) researchers, 5,413 (49.5 per cent) were mentioned 86,915 times in one of the 16 sources that Altmetric tracks. Twitter, news outlets and Facebook were among the sources that showed the most engagement with New Zealand 2016 research. Citation analysis tools in Dimensions showed that New Zealand 2016 research had a higher than average Field Citation Ratio (1.51) and Relative Citation Ratio (1.29). Originality/value This study combines traditional bibliometric analysis with altmetrics to find new insights into the impact of recent New Zealand research. It suggests new means for organizations to demonstrate the value of the research they produce.","tags":["Bibliometrics","Citation analysis","Altmetrics","Altmetric","Dimensions","New Zealand"],"title":"Altmetrics: “big data” that map the influence of New Zealand research","type":"publication"},{"authors":["Joshua Finnell","Stacy Konkiel"],"categories":null,"content":"","date":1506816000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1506816000,"objectID":"3a80a1e83b13de652f18832bb519f2fa","permalink":"https://skonkiel.github.io/publication/finnell-building-2017/","publishdate":"2020-04-12T22:26:37.927021Z","relpermalink":"/publication/finnell-building-2017/","section":"publication","summary":"This article is on overview of Library Pipeline, a grassroots library organization dedicated to supporting structural changes by providing opportunities, funding, and services that improve the library as an institution and librarianship as a profession.","tags":["innovation","Grants","library associations","nonprofits"],"title":"Building and Sustaining a Grassroots Library Organization: A Three-Year Retrospective of Library Pipeline","type":"publication"},{"authors":null,"categories":["Work \u0026 Research"],"content":"CC-BY Nicky Agate / Medium I’m excited to announce that the HuMetricsHSS research team–which I was a part of at the 2016 TriangleSCI conference–has received the support of the Andrew W. Mellon Foundation to continue our work of encouraging the discovery and use of “humane” research evaluation metrics for the humanities and social sciences.\nHSS scholars are increasingly frustrated by the prevalence of the use of evaluation metrics (borrowed from the sciences) that do not accurately capture the impacts of their work. Our grand vision is to develop better metrics, ones that are rooted in the values that are important to scholars. This grant-funded research is a start.\nFrom the press release:\n “We are reverse-engineering the way metrics have operated in higher education,” said Christopher P. Long, Dean of the College of Arts \u0026amp; Letters at Michigan State University and one of the Principal Investigators (PIs) of the Mellon-funded project. “We begin not with what can be measured technologically, but by listening to scholars themselves as they identify the practices of scholarship that enrich their work and connect it to a broader public.”\n We’ll be sharing updates on the HuMetricsHSS project from  our websiteand  on Twitter, so please follow along!\nMuch gratitude to the Mellon Foundation for supporting HuMetricsHSS.\n","date":1497974813,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497974813,"objectID":"a5c787e0e6e19ca1e9af9bf9d67ecbec","permalink":"https://skonkiel.github.io/mellon-humetrics-grant/","publishdate":"2017-06-20T16:06:53Z","relpermalink":"/mellon-humetrics-grant/","section":"post","summary":"CC-BY Nicky Agate / Medium I’m excited to announce that the HuMetricsHSS research team–which I was a part of at the 2016 TriangleSCI conference–has received the support of the Andrew W. Mellon Foundation to continue our work of encouraging the discovery and use of “humane” research evaluation metrics for the humanities and social sciences.\nHSS scholars are increasingly frustrated by the prevalence of the use of evaluation metrics (borrowed from the sciences) that do not accurately capture the impacts of their work.","tags":null,"title":"Mellon Grant to Support Values-Based Metrics for the Humanities and Social Sciences","type":"post"},{"authors":null,"categories":["General"],"content":"I just used a service called Cardigan to delete the 10k+ tweets I’ve published since 2007, when I first joined Twitter.\nI don’t know about you, but I’ve changed a lot since I was 24 years old.\nIt didn’t make sense to me to keep ten years worth of miscellany–silly jokes, uninformed hot takes, occasional sharp insights, and so on–up on the Internet, gathering dust, making advertising money for Twitter. I don’t want to support a company that even with a $10.8 billion valuation somehow can’t get it right and stop banning innocent users rather than the Nazis who are harrassing them.\nI don’t enjoy Twitter anymore. Over the years, Twitter has gone from a great place (to stay in touch with friends and former colleagues worldwide, to find interesting research and industry news, to meet new people) to one that seriously bums me out every time I log on (every day brings a new outrage, smart people sniping at each other, Mean Librarian Twitter, and unintelligible memes). It’s become superficial on a lot of levels. It’s often used as a tool to demean and call out rather than enrich and uplift.\nAll that said, I’m not going to delete my account outright. Twitter is still somewhat important professionally, so I’ll continue using it to share the occasional piece of research or to livetweet interesting conferences.\nBut I’d rather let my writing and research speak for itself, in longform. And for my personal and professional relationships to deepen, offline.\nI’ll be slowly unfollowing accounts who aren’t directly relevant to my interests or my work at Altmetric (sorry!) and hopefully logging on a lot less. I’ll also aim to delete my tweets and favorites every so often, to keep things fresh.\nIf you need me, email me at hello@stacykonkiel.org (personal) or stacy@altmetric.com (work).\nWith love and gratitude to my friends and followers for ten years of shitposting and networking…\nxx\n","date":1497648700,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497648700,"objectID":"0356d9f2a5ca8e257a2f6a2fb5915630","permalink":"https://skonkiel.github.io/deleted-twitter-history/","publishdate":"2017-06-16T21:31:40Z","relpermalink":"/deleted-twitter-history/","section":"post","summary":"I just used a service called Cardigan to delete the 10k+ tweets I’ve published since 2007, when I first joined Twitter.\nI don’t know about you, but I’ve changed a lot since I was 24 years old.\nIt didn’t make sense to me to keep ten years worth of miscellany–silly jokes, uninformed hot takes, occasional sharp insights, and so on–up on the Internet, gathering dust, making advertising money for Twitter. I don’t want to support a company that even with a $10.","tags":null,"title":"Why I just deleted my ten-year Twitter history","type":"post"},{"authors":["Sarah W. Sutton","Rachel Miles","Stacy Konkiel"],"categories":null,"content":"","date":1493596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493596800,"objectID":"5059bd3f4af0c3147695a6c9eb0141f3","permalink":"https://skonkiel.github.io/publication/sutton-is-2017/","publishdate":"2020-04-12T22:26:37.928819Z","relpermalink":"/publication/sutton-is-2017/","section":"publication","summary":"New forms of data like altmetrics are helping librarians to make smarter decisions about their collections. A recent nationwide study administered to librarians at R1 universities shines light on exactly how these metrics are being applied in academia. This article is based on a presentation from the NASIG 31st Annual Conference. It includes survey results addressing previously unknown rates of technology and metrics uptake among collection development librarians, the most popular citation databases and altmetrics services being used to make decisions, and surprising factors that affect attitudes toward the use of metrics.","tags":["bibliometrics","collection development","Altmetrics","survey","selection criteria"],"title":"Is What’s “Trending” What’s Worth Purchasing? Insights from a National Study of Collection Development Librarians","type":"publication"},{"authors":null,"categories":["Work \u0026 Research"],"content":"I’m super excited to announce that the Innovation in Libraries grant is now accepting applications: http://www.awesomefoundation.org/en/chapters/libraries\nA core group of Library Pipeliners has been working hard for months to recruit rank-and-file librarians worldwide, many of whom are funding this grant out of their own pockets (!). Each month through August 2017, our Awesome Foundation chapter will award a $1000 USD grant to prototype library-based innovations (both technical and non-technical in nature) that are inclusive, daring, and diverse.\nI am so proud of this grassroots effort to support risk-taking in librarianship. This is a great step towards building community through organizing, and I’m really excited to be a part of it.\nSpecial recognition goes to Josh Finnell (Los Alamos National Lab), Robin Champieux (OHSU), and Bonnie Tijerina (Data \u0026amp; Society/ER\u0026amp;L), all of whom were crucial to getting this project off the ground.\nFor more information on the grant, please do visit the grant webpage or apply via the Awesome Foundation.\n","date":1488386600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1488386600,"objectID":"caa1fc2abbc10e57784bcb1188560677","permalink":"https://skonkiel.github.io/innovation-micro-grant/","publishdate":"2017-03-01T16:43:20Z","relpermalink":"/innovation-micro-grant/","section":"post","summary":"I’m super excited to announce that the Innovation in Libraries grant is now accepting applications: http://www.awesomefoundation.org/en/chapters/libraries\nA core group of Library Pipeliners has been working hard for months to recruit rank-and-file librarians worldwide, many of whom are funding this grant out of their own pockets (!). Each month through August 2017, our Awesome Foundation chapter will award a $1000 USD grant to prototype library-based innovations (both technical and non-technical in nature) that are inclusive, daring, and diverse.","tags":null,"title":"Library Pipeline launches “Innovation in Libraries” micro-grant","type":"post"},{"authors":["Rui Araújo","Aaron A. Sorensen","Stacy Konkiel","Bastiaan R. Bloem"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"2abc0467594a33be18ba0efb24b3ed0d","permalink":"https://skonkiel.github.io/publication/araujo-top-2017/","publishdate":"2020-04-12T22:26:37.927899Z","relpermalink":"/publication/araujo-top-2017/","section":"publication","summary":"A new class of social web-based metrics for scholarly publications (altmetrics) has surfaced as a complement to traditional citation-based metrics. Our aim was to study and characterize those recent papers in the field of Parkinson’s disease which ha","tags":null,"title":"Top Altmetric Scores in the Parkinson’s Disease Literature","type":"publication"},{"authors":null,"categories":["Work \u0026 Research"],"content":"For the past few weeks, I’ve been working with a colleague at Altmetric to develop a guide for using altmetrics in one’s promotion and tenure dossier. (Keep an eye out for the resulting blog post and handout on Altmetric.com–I think they’re going to be good!)\nAltmetrics and P\u0026amp;T is a topic that’s come up a lot recently, and predictably the responses are usually one of the following:\n Do you seriously want to give people tenure based on their number of Twitter followers?!!?! ::rageface:: Hmm, that’s a pretty interesting idea! If applied correctly (i.e. in tandem with expert peer review and traditional metrics like citation counts, etc), I could see how altmetrics could improve the evaluation process for P\u0026amp;T.  You can probably guess how I lean.\nWith that in mind, I wanted to think aloud about an editorial I recently read in Inside Higher Ed (a bit late to the game–the essay was written in 2014). It’s a great summary of many of the issues that plague P\u0026amp;T here in the States, and in particular the bits about “legitimacy markers” make a great argument in favor of recognizing altmetrics in P\u0026amp;T evaluation and preparation guidelines.\nBelow, I’ve excerpted the parts [to which I want to respond] (and the bits I want to emphasize), but please visit Inside Higher Ed and read the piece in its entirety, it’s worth your time.\nThe assumption that we know a scholar’s work is excellent if it has been recognized by a very narrow set of legitimacy markers adds bias to the process and works against recognition of newer form of scholarship. [\u0026#8230;] Typically candidates for tenure and promotion submit a personal narrative describing their research, a description of the circulation, acceptance rate and impact factors of the journals or press where they published, a count and list of their citations, and material on external grants. This model of demonstration of impact favors certain disciplines over others, disciplinary as opposed to interdisciplinary work, and scholarship whose main purpose is to add to academic knowledge. [Emphasis mine.] In my view, the problem is not that using citation counts and journal impact factors is “a” way to document the quantity and quality of one’s scholarship. The problem is that it has been normalized as the only way. All other efforts to document scholarship and contributions \u0026#8212; whether they be for interdisciplinary work, work using critical race theory or feminist theory, qualitative analysis, digital media or policy analysis are then suspect, marginalized, and less than. Using the prestige of academic book presses, citation counts and federal research awards to judge the quality of scholarship whose purpose is to directly engage with communities and public problems misses the point. Interdisciplinary and engaged work on health equity should be measured by its ability to affect how doctors act and think. [One might argue that altmetrics like citations in public policy documents and clinical care guidelines are a good proxy for this.] Research on affirmative action in college admissions should begin to shape admissions policies. [Perhaps such evidence could be sourced from press releases and mainstream media coverage of said changes in admissions policies.] One may find key theoretical and research pieces in these areas published in top tier journals and cited in the Web of Science, but they should also find them in policy reports cited at NIH [again, citations in policy docs useful here], or used by a local hospital board to reform doctor training [mining training handbooks and relevant websites could help locate such evidence]. We should not be afraid to look for impact of scholarship there, or give that evidence credibility. Work that is addressing contemporary social problems deserves to be evaluated by criteria better suited to its purposes and not relegated to the back seat behind basic or traditional scholarship. Altmetrics technologies aren’t yet advanced enough to do most of the things I’ve suggested above (in particular, to mine news coverage or the larger Web for mentions of the effects of research, rather than links to research articles themselves). But the field is very young, and I expect we’ll get there soon enough. And in the meantime, we’ve got some pretty decent proxies for true impact already in the main altmetrics services (i.e. policy citations in Altmetric Explorer, clinical citations in PlumX, dependency PageRank for useful software projects in Depsy/Impactstory).\nIn the shorter term, we need for academics to advocate for the inclusion of altmetrics in promotion \u0026amp; tenure evaluation and preparation guidelines.\nMost researchers don’t know that this data is available, so they tend not to use it in preparing their dossiers. Fair enough.\nWhat concerns me are the researchers who are aware of altmetrics, but who are hesitant to include it in their dossiers for fear that their colleagues a) won’t know what to do with the data, or b) won’t take them seriously if they include it. After all, there’s a lot of misinformation out there about what altmetrics are meant to do, and if you’ve got a reviewer that’s misinformed or that has a bone to pick re: altmetrics, that could potentially affect your career.\nThen there’s the tenure committees, often made up of reviewers from all disciplines and at all (post-tenure) stages of their career. If they’re presented with altmetrics as evidence in a P\u0026amp;T dossier but a) they’re biased against altmetrics, and/or b) their university’s review guidelines don’t confirm that altmetrics–in the service of providing evidence for specific claims to impact–are a respectable form of evidence for one’s dossier, then the tenure applicant is either met with confusion or skepticism (at best) or responded to with outright hostility (at worst).\n(Before you think I’m being melodramatic re: “outright hostility”–you should see some of the anti-altmetrics diatribes out there. As in many other aspects of life, some people aren’t content with the “you do it your way, I’ll do it my way” thing–they are pissed that you dare to challenge the status quo and will attack those who suggest differently.)\nAnyone reading this post that’s got a modicum of influence at their university (i.e. you’ve got tenure status and/or voting rights on your university’s faculty council) should go and petition their vice provost of faculty affairs to update their university-wide P\u0026amp;T review and preparation guidelines to include altmetrics. Or, at the very least, focus on changing departmental/college P\u0026amp;T guidelines.\nOnce you’ve done so, we’re that much closer to reforming the P\u0026amp;T process to respect the good work that’s being done by all academics, not just those who meet a very traditional set of criteria.\n","date":1473200541,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1473200541,"objectID":"e43ee69ec94e43e664bf77f5e1a68022","permalink":"https://skonkiel.github.io/altmetrics-promotion-tenure/","publishdate":"2016-09-06T22:22:21Z","relpermalink":"/altmetrics-promotion-tenure/","section":"post","summary":"For the past few weeks, I’ve been working with a colleague at Altmetric to develop a guide for using altmetrics in one’s promotion and tenure dossier. (Keep an eye out for the resulting blog post and handout on Altmetric.com–I think they’re going to be good!)\nAltmetrics and P\u0026amp;T is a topic that’s come up a lot recently, and predictably the responses are usually one of the following:\n Do you seriously want to give people tenure based on their number of Twitter followers?","tags":null,"title":"Altmetrics and the reform of the promotion \u0026 tenure system","type":"post"},{"authors":["Stacy Konkiel"],"categories":null,"content":"","date":1470009600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1470009600,"objectID":"6da656ef7566f457757e1aa972cd5acc","permalink":"https://skonkiel.github.io/publication/konkiel-altmetrics-2016/","publishdate":"2020-04-12T22:26:37.922421Z","relpermalink":"/publication/konkiel-altmetrics-2016/","section":"publication","summary":"","tags":null,"title":"Altmetrics: diversifying the understanding of influential scholarship","type":"publication"},{"authors":null,"categories":["Work \u0026 Research"],"content":"An article I co-authored along with Cassidy Sugimoto (Indiana University) and Sierra Williams (LSE Impact Blog) was recently published in the Educause Review.\nFrom the intro: “Promotion and tenure decisions in the United States often rely on various scientometric indicators (e.g., citation counts and journal impact factors) as a proxy for research quality and impact. Now a new class of metrics — altmetrics — can help faculty provide impact evidence that citation-based metrics might miss: for example, the influence of research on public policy or culture, the introduction of lifesaving health interventions, and contributions to innovation and commercialization. But to do that, college and university faculty and administrators alike must take more nuanced, responsible, and informed approaches to using metrics for promotion and tenure decisions”\n Read the full article on the Educause Review website.\n","date":1461805481,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461805481,"objectID":"d739e75006f4008163f63e9a417781f2","permalink":"https://skonkiel.github.io/altmetrics-in-promotion-tenure-educause-review/","publishdate":"2016-04-28T01:04:41Z","relpermalink":"/altmetrics-in-promotion-tenure-educause-review/","section":"post","summary":"An article I co-authored along with Cassidy Sugimoto (Indiana University) and Sierra Williams (LSE Impact Blog) was recently published in the Educause Review.\nFrom the intro: “Promotion and tenure decisions in the United States often rely on various scientometric indicators (e.g., citation counts and journal impact factors) as a proxy for research quality and impact. Now a new class of metrics — altmetrics — can help faculty provide impact evidence that citation-based metrics might miss: for example, the influence of research on public policy or culture, the introduction of lifesaving health interventions, and contributions to innovation and commercialization.","tags":null,"title":"“The Use of Altmetrics in Promotion and Tenure” published in Educause Review","type":"post"},{"authors":null,"categories":["EVENTS","Work \u0026 Research"],"content":"_[Cross-posted from the Digital Science blog on 25th April 2016 ][1]_  \u0026nbsp;   Join us for a Reddit Ask Me Anything with Stacy Konkiel (@skonkiel), Outreach \u0026 Engagement Manager at Altmetric, at 6pm GMT/1pm EDT on the 10th May.  The Reddit Ask Me Anything forum is a great way to engage and interact with subject experts in a direct and honest Q\u0026A, asking those burning questions you’ve always wanted to get their perspective on! Mark Hahnel, the founder of Figshare, Euan Adie, the founder of Altmetric and John Hammersley, co-founder of Overleaf, have also all participated in this popular discussion forum.  Following their lead, on Tuesday 10th May at 6pm UK time / 1pm EST Stacy Konkiel, Altmetric’s Outreach \u0026 Engagement Manager, will be taking part in an AMA on the AskScience subreddit.   Stacy plans to talk about what the metrics and indicators we like to rely upon in science (impact factor, altmetrics, citation counts, etc) to understand “broader impact” and “intellectual merit,” are actually measuring what we purport they measure.  She is not sure they do! And instead thinks that right now, we’re just using rough proxies to understand influence and attention. We’re in danger of abusing the metrics that are supposed to save us all, altmetrics, just like science has done with the journal impact factor.  Stacy will talk about improving measures of research impact, but is also open to taking other relevant questions.  If you wish to participate in the Ask Me Anything, you will need to register with Reddit. There will also be some live tweeting from @altmetric and @digitalsci, and questions on the #AskStacyAltmetric hashtag, so keep your eyes peeled!  ","date":1461602403,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461602403,"objectID":"aede365d62c46a8936916ec67ae7666a","permalink":"https://skonkiel.github.io/reddit-ama-may-2016/","publishdate":"2016-04-25T16:40:03Z","relpermalink":"/reddit-ama-may-2016/","section":"post","summary":"_[Cross-posted from the Digital Science blog on 25th April 2016 ][1]_  \u0026nbsp;   Join us for a Reddit Ask Me Anything with Stacy Konkiel (@skonkiel), Outreach \u0026 Engagement Manager at Altmetric, at 6pm GMT/1pm EDT on the 10th May.  The Reddit Ask Me Anything forum is a great way to engage and interact with subject experts in a direct and honest Q\u0026A, asking those burning questions you’ve always wanted to get their perspective on!","tags":null,"title":"Reddit AMA – May 10th!","type":"post"},{"authors":null,"categories":["Work \u0026 Research"],"content":"I’m pleased to report that along with the team behind Radian (a knowledge portal for data management librarians), the Metric Tookit (pitched by me, Heather Coates, and Robin Champieux) has won the Force 2016 PitchIt Innovation Challenge!\nI’m hugely proud and very excited about bringing this idea to life. In talking with researchers and librarians worldwide over the past two years, the single biggest request I tend to get is an easy way to understand what metrics really mean (or more importantly, what they don’t mean). This toolkit will be that resource.\nWe’ve already started to get some promising feedback about our plans, including these nice tweets from (one of my favorite open scientists :)) Erin McKiernan and Sara Mannheimer:\nAgreed, think this is a very cool idea! #force2016 #innovationchallenge #metrics https://t.co/yAI5UAi4BO  — Erin McKiernⓐn (@emckiernan13) April 19, 2016  To learn more about our vision, visit the Jisc Elevator site, where we’ve submitted our pitch and an accompanying video.\nMany thanks to Heather and Robin, who were the driving force behind developing such a compelling pitch deck! And thank you also to the Force11 community–we look forward to sharing our results with you soon!\n","date":1461161781,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461161781,"objectID":"fea43af8fd20c86f5b2ddcbc8ded908e","permalink":"https://skonkiel.github.io/force2016-innovation-challenge/","publishdate":"2016-04-20T14:16:21Z","relpermalink":"/force2016-innovation-challenge/","section":"post","summary":"I’m pleased to report that along with the team behind Radian (a knowledge portal for data management librarians), the Metric Tookit (pitched by me, Heather Coates, and Robin Champieux) has won the Force 2016 PitchIt Innovation Challenge!\nI’m hugely proud and very excited about bringing this idea to life. In talking with researchers and librarians worldwide over the past two years, the single biggest request I tend to get is an easy way to understand what metrics really mean (or more importantly, what they don’t mean).","tags":null,"title":"Results of the #Force2016 Innovation Challenge: we won!","type":"post"},{"authors":["Stacy Konkiel","Cassidy R Sugimoto","Sierra Williams"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"07c732617d02f64f5f57c0e6ab774524","permalink":"https://skonkiel.github.io/publication/konkiel-use-2016/","publishdate":"2020-04-12T22:26:37.916801Z","relpermalink":"/publication/konkiel-use-2016/","section":"publication","summary":"Promotion and tenure decisions in the United States often rely on various scientometric indicators (e.g., citation counts and journal impact factors) as a proxy for research quality and impact. Now a new class of metrics—altmetrics—can help faculty pro- vide impact evidence that citation-based metrics might miss: for example, the influence of research on public policy or culture, the introduction of live-saving health interventions, and con- tributions to innovation and commercialization. But to do that, college and university faculty and administrators alike must take more nuanced, responsible, and informed approaches to using metrics","tags":null,"title":"The use of Altmetrics in promotion and tenure","type":"publication"},{"authors":null,"categories":["Work \u0026 Research"],"content":"I’m currently working with Sarah Sutton at Emporia State University on launching a survey to get a sense of how librarians use altmetrics, including for collection development purposes. (Is it useful to know if a book has been cited in a policy document, even if it’s rarely circulated, so you don’t deaccession it? Can monitoring online activity for all scholarship–even articles that a library doesn’t have subscription access to–help librarians make much quicker purchasing decisions for articles and journals that patrons might request? And so on.)\nSo it was with a lot of interest that I read Chris Bourg’s “ Infrastructure and Culture: A job talk” yesterday. In the talk (which rightly landed her the position of Director of MIT Libraries, at least in part), Bourg describes how institutional cultures are so important to (among other things) the failure or success of campus scholarly communication initiatives.\nCrucially, she talks about the unintended consequences that a culture of quantification can have upon decisions that are made for library collections, especially collections that might not be popular but that might inform important research projects, like this study that uses old, uncirculated volumes to study the evolution of Brazilian Portuguese over time.\nI encourage you to read Bourg’s post in its entirety, but wanted to pull out one section in particular that I think is a valuable way to think about assessment and metrics w/r/t library services:\nDeveloping new ways of demonstrating the impact of our services and collections is a way of promoting a culture that values assessment, but also recognizes that the true impact of libraries and librarians is often delayed and too idiosyncratic to show up in most of the standard ROI style assessment tools currently in use. So while I am a fan of assessment and data-driven decision-making, I think it is critically important that we make sure the data we are using captures the full story of our impact. As a social scientist with experience teaching and consulting on statistics and research methods, I’m committed to making sure that the assessment tools we use in libraries are the right ones, that the data we collect measures what really matters, and that we use methods appropriate to the decisions we want to make. In this spirit, I ask: what methods are you using to drive collection development at your library? And how might you use metrics (including altmetrics) in a more nuanced way to achieve goals that are in line with your larger library (and institutional) culture?\nPS Keep your eyes on your inbox–if you’re a librarian at an R1 institution in the US, I’ll likely be emailing you soon to ask you to participate in our survey on altmetrics and libraries.\n","date":1436888713,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1436888713,"objectID":"d00e1a63a657bc33830ab51f5ee49256","permalink":"https://skonkiel.github.io/metrics-collection-management/","publishdate":"2015-07-14T15:45:13Z","relpermalink":"/metrics-collection-management/","section":"post","summary":"I’m currently working with Sarah Sutton at Emporia State University on launching a survey to get a sense of how librarians use altmetrics, including for collection development purposes. (Is it useful to know if a book has been cited in a policy document, even if it’s rarely circulated, so you don’t deaccession it? Can monitoring online activity for all scholarship–even articles that a library doesn’t have subscription access to–help librarians make much quicker purchasing decisions for articles and journals that patrons might request?","tags":["altmetrics","assessment","collection development","libraries"],"title":"The case against (only) using metrics for collection management","type":"post"},{"authors":null,"categories":["Work \u0026 Research"],"content":"Humanities researchers I’ve talked to usually fall into one of two camps when it comes to altmetrics:\n “Altmetrics are amazing! I’ve been looking for a better way to understand the use and impacts of my work.” or “This is just another tool that favors the sciences and tries to reduce the complexities of my research into a single formula. It will never work for me.”  As an altmetrics advocate and humanist by training, I unsurprisingly tend to fall into the first camp.\nI’ve been doing a lot of reading and thinking lately on how research is evaluated in the humanities, and it seems to sadly be as an opaque of a process as in the sciences. By and large, you’re judged by:\n the university press you’ve published your book(s) with, reviews that other scholars write about your books, and occasionally, by the citations your journal articles and books receive  Unsurprisingly, this framework tends to favors books and, to a lesser extent, journal articles. The value of digital scholarship projects (websites, interactive exhibitions, etc), software, and research data aren’t taken into account under this model. Thank goodness that’s starting to change.\nIn the past few years, scholarly societies and some universities have created guidelines to help traditionalists understand the impacts of digital scholarship projects. Faculty are encouraged to think beyond the monograph when considering what types of work might have a lasting influence on the profession.\nBut these guidelines tend not to address newer types of quantitative and qualitative data, sourced from the web, that can help reviewers understand the full scope of the impacts your work may have. This data can include newer impact metrics like numbers of website visitors, what other scholars are saying about your work on their research blogs and social media, how many members of the public have reviewed your books on GoodReads and Amazon, and so on.\nThat’s where my current work comes in.\nI’m now in the process of talking with humanities researchers, from department chairs to graduate students, to better understand what types of data might be useful in supplementing their understanding of impacts for digital humanities research.\nAnd I’ve done two talks in the past week– one at the ASIS\u0026amp;T Virtual Symposium on Information Technology in the Arts \u0026amp; Humanities, and one at the Advancing Research Communication \u0026amp; Scholarship meeting.\nBoth talks were intended to get conversations started about altmetrics and the humanities–what might work, what would never work, what data sources could potentially be tracked that aren’t yet included in services like Altmetric and PlumX.\nI’ll be doing more researching, writing, thinking and speaking on the topic in the coming months–stay tuned for more information.\nIn the meantime, I’d love to get your feedback in the comments below.\n","date":1430326260,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1430326260,"objectID":"c1f3594f7905041e704b64977d9103a6","permalink":"https://skonkiel.github.io/were-overdue-on-altmetrics-for-the-digital-humanities/","publishdate":"2015-04-29T16:51:00Z","relpermalink":"/were-overdue-on-altmetrics-for-the-digital-humanities/","section":"post","summary":"Humanities researchers I’ve talked to usually fall into one of two camps when it comes to altmetrics:\n “Altmetrics are amazing! I’ve been looking for a better way to understand the use and impacts of my work.” or “This is just another tool that favors the sciences and tries to reduce the complexities of my research into a single formula. It will never work for me.”  As an altmetrics advocate and humanist by training, I unsurprisingly tend to fall into the first camp.","tags":null,"title":"We’re overdue on altmetrics for the digital humanities","type":"post"},{"authors":["Stacy Konkiel","Heather Piwowar","Jason Priem"],"categories":null,"content":"","date":1409529600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1409529600,"objectID":"8d79cf28f9f44f3141acbf4e6e8dd94d","permalink":"https://skonkiel.github.io/publication/konkiel-imperative-2014/","publishdate":"2020-04-12T22:26:37.913719Z","relpermalink":"/publication/konkiel-imperative-2014/","section":"publication","summary":"If scholarly communication is broken, how will we fix it? At Impactstory-a non-profit devoted to helping scholars gather and share evidence of their research impact by tracking online usage of scholarship via blogs, Wikipedia, Mendeley, and more-we believe that incentivizing web-native research via altmetrics is the place to start. In this article, we describe the current state of the art in altmetrics and its effects on publishing, we share Impactstory's plan to build an open infrastructure for altmetrics, and describe our company's ethos and actions.","tags":["open access","altmetrics","open data"],"title":"Imperative for Open Altmetrics","type":"publication"},{"authors":["Stacy Konkiel"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"49b6b8672568e0100fc339e108b3bb03","permalink":"https://skonkiel.github.io/publication/konkiel-30-day-2014/","publishdate":"2020-04-12T22:26:37.920181Z","relpermalink":"/publication/konkiel-30-day-2014/","section":"publication","summary":"","tags":["altmetrics","open science","science communication"],"title":"The 30-Day Impact Challenge: the ultimate guide to raising the profile of your research","type":"publication"},{"authors":["Stacy Konkiel","Dave Scherer"],"categories":null,"content":"","date":1364774400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1364774400,"objectID":"6685470460dea0a07d7fd8181f8d8064","permalink":"https://skonkiel.github.io/publication/konkiel-new-2013/","publishdate":"2020-04-12T22:26:37.920883Z","relpermalink":"/publication/konkiel-new-2013/","section":"publication","summary":"","tags":["altmetrics","repositories"],"title":"New opportunities for repositories in the age of altmetrics","type":"publication"},{"authors":["S. Konkiel"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"7c6d8bd1a9e8c9a40c65e1e2ea2e42f7","permalink":"https://skonkiel.github.io/publication/konkiel-altmetrics-2013/","publishdate":"2020-04-12T22:26:37.918704Z","relpermalink":"/publication/konkiel-altmetrics-2013/","section":"publication","summary":"","tags":null,"title":"Altmetrics a 21 st-century solution to determining research quality","type":"publication"},{"authors":["Stacy Konkiel"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"97a0ab697a894acafae478adbedc6b9f","permalink":"https://skonkiel.github.io/publication/konkiel-tracking-2013/","publishdate":"2020-04-12T22:26:37.919449Z","relpermalink":"/publication/konkiel-tracking-2013/","section":"publication","summary":"","tags":null,"title":"Tracking citations and altmetrics for research data: Challenges and opportunities","type":"publication"}]